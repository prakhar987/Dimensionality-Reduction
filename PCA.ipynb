{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "lines = open('./dorothea_train.data').read().splitlines() ## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Declare Empty X matrix\n",
    "tmp=np.zeros(shape=(800,100000))\n",
    "X=pd.DataFrame(tmp)\n",
    "\n",
    "# Now fill X matrix\n",
    "for i in range(0,len(lines)):\n",
    "    row=lines[i]\n",
    "    row=row.split()\n",
    "    row = list(map(int, row)) ## convert string indexes as int indexes\n",
    "    row=np.array(row) ## Convert to numpy array to apply arithmetic operation\n",
    "    row=row-1 ## convert index from 1 to 100000 to 0 to 99999\n",
    "    X.ix[i][row]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculated Centred Matrix A\n",
    "mean=X.mean()\n",
    "A=X-mean\n",
    "A=A.as_matrix()   ## Convert to numpy from DF\n",
    "A=np.transpose(A) ## A is d*n\n",
    "At=np.transpose(A)\n",
    "X=X.as_matrix()\n",
    "X=np.transpose(X)   ## X is now d*n\n",
    "# Finally A is centred data, X is normal data , both being d*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K=np.dot(At,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp=np.linalg.eig(K)\n",
    "eign_values=tmp[0]\n",
    "eign_vector=tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Choose 'k' biggest eign vectors\n",
    "num_of_comp=800 #all DUMMY\n",
    "indexes = eign_values.argsort()[::-1]\n",
    "eign_vector = eign_vector[:, indexes[0:num_of_comp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W=np.dot(A,eign_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootlmda=np.sqrt(eign_values)\n",
    "W=W/rootlmda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Reducing to 100 \n",
    "# W=np.transpose(W)\n",
    "features=800\n",
    "W=W[:,:features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reducedA=np.dot(np.transpose(W),X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Bring back to normal representation\n",
    "reducedA=np.transpose(reducedA)\n",
    "## Now reducedA is datapoints (n*d) in reduced Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########################################## PCA IS COMPLETE ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## READ TEST DATA ##########################\n",
    "lines_test=open('./dorothea_valid.data').read().splitlines() ## Test\n",
    "# Declare Empty X matrix\n",
    "tmp=np.zeros(shape=(350,100000))\n",
    "X_test=pd.DataFrame(tmp)\n",
    "\n",
    "# Now fill X matrix\n",
    "for i in range(0,len(lines_test)):\n",
    "    row=lines_test[i]\n",
    "    row=row.split()\n",
    "    row = list(map(int, row)) ## convert string indexes as int indexes\n",
    "    row=np.array(row) ## Convert to numpy array to apply arithmetic operation\n",
    "    row=row-1 ## convert index from 1 to 100000 to 0 to 99999\n",
    "    X_test.ix[i][row]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=X_test.as_matrix()\n",
    "X_test=np.transpose(X_test)   ## X_test is now d*n\n",
    "reduced_X_test=np.dot(np.transpose(W),X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Bring back to normal representation\n",
    "reduced_X_test=np.transpose(reduced_X_test)\n",
    "## Now reducedA is datapoints (n*d) in reduced Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Divide data in train and test\n",
    "train=reducedA\n",
    "test=reduced_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now start Training \n",
    "#Read lables\n",
    "lines = open('./dorothea_train.labels').read().splitlines()\n",
    "lines_test = open('./dorothea_valid.labels').read().splitlines()\n",
    "train_lables=lines\n",
    "test_lables=lines_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Split train data according to classes\n",
    "#Add class lables to data\n",
    "df=pd.DataFrame(train)\n",
    "tmp=pd.Series(train_lables)\n",
    "df.loc[:,features+1]=tmp\n",
    "#Now split as per lables\n",
    "df0=df[df[features+1]=='-1'] \n",
    "df1=df[df[features+1]=='1']  \n",
    "\n",
    "## Remove class lables now\n",
    "del df0[features+1] ## DF containing class -1 \n",
    "del df1[features+1] ## DF containing class +1\n",
    "## convert to numpy arrays\n",
    "class0=df0.as_matrix()\n",
    "class1=df1.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now find mean and covariance\n",
    "u1=class0.mean(0)\n",
    "u2=class1.mean(0)\n",
    "e1=np.cov(class0,rowvar=False)\n",
    "e2=np.cov(class1,rowvar=False) \n",
    "## Also calculate posterior prob\n",
    "class0_pos=len(class0)/len(train)\n",
    "class1_pos=len(class1)/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "co1=e1.diagonal()\n",
    "co2=e2.diagonal()\n",
    "co1=np.dot(np.transpose(co1),co1)\n",
    "co2=np.dot(np.transpose(co2),co2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9028571428571428\n"
     ]
    }
   ],
   "source": [
    "## Calculate p(x) from Gaussian Formula\n",
    "import math\n",
    "count=0\n",
    "for i in range (0 , len(test)):\n",
    "    ## CLass 0\n",
    "    sample=test[i]\n",
    "    sm=0\n",
    "    for j in range (0,len(sample)): \n",
    "        xminusu=(sample[j]-u1[j])\n",
    "        xminusu=xminusu * xminusu\n",
    "        tmp=xminusu/e1[j][j]\n",
    "        tmp=tmp*(-0.5)\n",
    "        e=math.exp(tmp)\n",
    "        e=e/(math.sqrt(2*math.pi*e1[j][j]))\n",
    "        sm=sm+e\n",
    "    p0=sm*class0_pos\n",
    "    \n",
    "    ## Class 1\n",
    "    sample=test[i]\n",
    "    sm=0\n",
    "    for j in range (0,len(sample)): \n",
    "        xminusu=(sample[j]-u2[j])\n",
    "        xminusu=xminusu * xminusu\n",
    "        tmp=xminusu/e2[j][j]\n",
    "        tmp=tmp*(-0.5)\n",
    "        e=math.exp(tmp)\n",
    "        e=e/(math.sqrt(2*math.pi*e2[j][j]))\n",
    "        sm=sm+e\n",
    "    p1=sm*class1_pos\n",
    "    \n",
    "    \n",
    "    if(p0>p1):\n",
    "        result='-1'\n",
    "    else : \n",
    "        result='1'\n",
    "    if(result==test_lables[i]):\n",
    "        count+=1\n",
    "    \n",
    "\n",
    "print(float(count)/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "abc=GaussianNB()\n",
    "abc.fit(train,train_lables)\n",
    "print(abc.score(test,test_lables))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
