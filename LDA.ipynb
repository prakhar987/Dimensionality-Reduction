{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "lines = open('./dorothea_train.data').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Declare Empty X matrix\n",
    "tmp=np.zeros(shape=(800,100000))\n",
    "X=pd.DataFrame(tmp)\n",
    "\n",
    "# Now fill X matrix\n",
    "for i in range(0,len(lines)):\n",
    "    row=lines[i]\n",
    "    row=row.split()\n",
    "    row = list(map(int, row)) ## convert string indexes as int indexes\n",
    "    row=np.array(row) ## Convert to numpy array to apply arithmetic operation\n",
    "    row=row-1 ## convert index from 1 to 100000 to 0 to 99999\n",
    "    X.ix[i][row]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculated Centred Matrix A\n",
    "mean=X.mean()\n",
    "A=X-mean\n",
    "A=A.as_matrix()   ## Convert to numpy from DF\n",
    "X=X.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read lables\n",
    "lines = open('./dorothea_train.labels').read().splitlines()\n",
    "train_lables=lines   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Prepare train and test data\n",
    "features=1000\n",
    "data=X[:,:features] ## Select 1,000 features\n",
    "train=data\n",
    "\n",
    "df=pd.DataFrame(train)\n",
    "tmp=pd.Series(train_lables)\n",
    "df.loc[:,features]=tmp\n",
    "\n",
    "#Now split as per lables\n",
    "df0=df[df[features]=='-1'] \n",
    "df1=df[df[features]=='1']  \n",
    "## Remove class lables now\n",
    "del df0[features] ## DF containing class -1 \n",
    "del df1[features] ## DF containing class +1\n",
    "## convert to numpy arrays\n",
    "class0=df0.as_matrix()\n",
    "class1=df1.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########################################## LDA ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=data.mean(0)\n",
    "m1=class0.mean(0)\n",
    "m2=class1.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Within Class\n",
    "A1=class0-m1\n",
    "A2=class1-m2\n",
    "S1 = np.dot(A1.T, A1)\n",
    "S2 = np.dot(A2.T, A2)\n",
    "SW = S1 + S2 + np.identity(len(S1[0]))\n",
    "SW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Between Class\n",
    "SB = 0\n",
    "M1 = m1.reshape(1000,1) - m.reshape(1000,1)\n",
    "temp = np.dot(M1, M1.T)\n",
    "temp = len(class0)*temp\n",
    "SB+=temp\n",
    "\n",
    "M2 = m2.reshape(1000,1) - m.reshape(1000,1)\n",
    "temp = np.dot(M2, M2.T)\n",
    "temp = len(class1)*temp\n",
    "SB += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_features=2\n",
    "F = np.dot(np.linalg.inv(SW), SB)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(F)\n",
    "## Sort\n",
    "indexes = eigen_values.argsort()[::-1]\n",
    "transformation = eigen_vectors[:, indexes[0:reduced_features]] ## Set num of features to choose\n",
    "\n",
    "## Transform\n",
    "Xlda = np.dot(train, transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prakhar/Downloads/enter/lib/python3.5/site-packages/numpy/core/numeric.py:533: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "## Plot the scattered Points\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.plot(Xlda, 'ro')\n",
    "# plt.show()\n",
    "plt.scatter(Xlda[:,0], Xlda[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## READ TEST DATA ##########################\n",
    "lines_test=open('./dorothea_valid.data').read().splitlines() ## Test\n",
    "# Declare Empty X matrix\n",
    "tmp=np.zeros(shape=(350,100000))\n",
    "X_test=pd.DataFrame(tmp)\n",
    "\n",
    "# Now fill X matrix\n",
    "for i in range(0,len(lines_test)):\n",
    "    row=lines_test[i]\n",
    "    row=row.split()\n",
    "    row = list(map(int, row)) ## convert string indexes as int indexes\n",
    "    row=np.array(row) ## Convert to numpy array to apply arithmetic operation\n",
    "    row=row-1 ## convert index from 1 to 100000 to 0 to 99999\n",
    "    X_test.ix[i][row]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=X_test.as_matrix()\n",
    "X_test=X_test[:,:features] ## Select 1,000 features\n",
    "# X_test=np.transpose(X_test)   ## X_test is now d*n\n",
    "\n",
    "# Transform\n",
    "X_test_trasformed = np.dot(X_test, transformation)\n",
    "X_test_trasformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################### BAyes ##############################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=Xlda\n",
    "test=X_test_trasformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #Read lables\n",
    "lines_test = open('./dorothea_valid.labels').read().splitlines()\n",
    "test_lables=lines_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split train data according to classes\n",
    "#Add class lables to data\n",
    "df=pd.DataFrame(train)\n",
    "tmp=pd.Series(train_lables)\n",
    "df.loc[:,reduced_features+1]=tmp\n",
    "#Now split as per lables\n",
    "df0=df[df[reduced_features+1]=='-1'] \n",
    "df1=df[df[reduced_features+1]=='1']  \n",
    "\n",
    "## Remove class lables now\n",
    "del df0[reduced_features+1] ## DF containing class -1 \n",
    "del df1[reduced_features+1] ## DF containing class +1\n",
    "## convert to numpy arrays\n",
    "class0=df0.as_matrix()\n",
    "class1=df1.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now find mean and covariance\n",
    "u1=class0.mean(0)\n",
    "u2=class1.mean(0)\n",
    "e1=np.cov(class0,rowvar=False)\n",
    "e2=np.cov(class1,rowvar=False) \n",
    "## Also calculate posterior prob\n",
    "class0_pos=len(class0)/len(train)\n",
    "class1_pos=len(class1)/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co1=e1.diagonal()\n",
    "co2=e2.diagonal()\n",
    "co1=np.dot(np.transpose(co1),co1)\n",
    "co2=np.dot(np.transpose(co2),co2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8971428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prakhar/Downloads/enter/lib/python3.5/site-packages/ipykernel/__main__.py:13: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/home/prakhar/Downloads/enter/lib/python3.5/site-packages/ipykernel/__main__.py:14: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/home/prakhar/Downloads/enter/lib/python3.5/site-packages/ipykernel/__main__.py:26: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/home/prakhar/Downloads/enter/lib/python3.5/site-packages/ipykernel/__main__.py:27: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "## Calculate p(x) from Gaussian Formula\n",
    "import math\n",
    "count=0\n",
    "for i in range (0 , len(test)):\n",
    "    ## CLass 0\n",
    "    sample=test[i]\n",
    "    sm=0\n",
    "    for j in range (0,len(sample)): \n",
    "        xminusu=(sample[j]-u1[j])\n",
    "        xminusu=xminusu * xminusu\n",
    "        tmp=xminusu/e1[j][j]\n",
    "        tmp=tmp*(-0.5)\n",
    "        e=math.exp(tmp)\n",
    "        e=e/(math.sqrt(2*math.pi*e1[j][j]))\n",
    "        sm=sm+e\n",
    "    p0=sm*class0_pos\n",
    "    \n",
    "    ## Class 1\n",
    "    sample=test[i]\n",
    "    sm=0\n",
    "    for j in range (0,len(sample)): \n",
    "        xminusu=(sample[j]-u2[j])\n",
    "        xminusu=xminusu * xminusu\n",
    "        tmp=xminusu/e2[j][j]\n",
    "        tmp=tmp*(-0.5)\n",
    "        e=math.exp(tmp)\n",
    "        e=e/(math.sqrt(2*math.pi*e2[j][j]))\n",
    "        sm=sm+e\n",
    "    p1=sm*class1_pos\n",
    "    \n",
    "    \n",
    "    if(p0>p1):\n",
    "        result='-1'\n",
    "    else : \n",
    "        result='1'\n",
    "    if(result==test_lables[i]):\n",
    "        count+=1\n",
    "    \n",
    "\n",
    "print(float(count)/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prakhar/Downloads/enter/lib/python3.5/site-packages/sklearn/naive_bayes.py:378: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  self.theta_[i, :] = new_theta\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "abc=GaussianNB()\n",
    "abc.fit(train,train_lables)\n",
    "print(abc.score(test,test_lables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
